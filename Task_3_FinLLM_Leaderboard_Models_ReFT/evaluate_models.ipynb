{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cS0GtlOYJh4"
      },
      "source": [
        "**Important: When you run, make sure you choose runtime A100 GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3E8BvAE5GEM"
      },
      "source": [
        "Git and install libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch"
      ],
      "metadata": {
        "id": "6S7-p4R5K-cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b working https://github.com/GhostOf0days/PIXIU.git --recursive\n",
        "%cd PIXIU\n",
        "!pip install -r requirements.txt\n",
        "%cd /content/PIXIU/src/financial-evaluation\n",
        "!pip install -e .[multilingual]\n",
        "!pip install bert_score\n",
        "!pip install gdown\n",
        "!pip install vllm==0.5.4\n",
        "!pip install torch==2.4.0 torchvision==0.19\n",
        "!pip install peft\n",
        "!pip install lm-eval google-generativeai"
      ],
      "metadata": {
        "id": "UWUqXqcac988"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fosY1vFA5N5E"
      },
      "source": [
        "Download BART checkpoint to src/metrics/BARTScore/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3EeA1fScj_7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import gdown\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "source_path = \"/content/drive/My Drive/bart_score.pth\"\n",
        "destination_path = \"/content/PIXIU/src/metrics/BARTScore/bart_score.pth\"\n",
        "\n",
        "if os.path.exists(source_path) and not os.path.exists(destination_path):\n",
        "    !cp \"{source_path}\" \"{destination_path}\"\n",
        "    print(\"File found in Google Drive and copied.\")\n",
        "else:\n",
        "    file_id = '19Fpob1RhQHyvMlOqxPO89z1W58PvkOm-'\n",
        "    url = f'https://drive.google.com/uc?id={file_id}'\n",
        "    gdown.download(url, destination_path, quiet=False)\n",
        "    print(\"File not found in Google Drive. Downloaded instead.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPovkuRT5VA4"
      },
      "outputs": [],
      "source": [
        "%cd /content/PIXIU/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpV3xb7PTKnO"
      },
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15rbRZfMJlWe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['PYTHONPATH'] += \":/content/PIXIU/src/metrics/BARTScore/\"\n",
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45lcr7ikF3NC"
      },
      "source": [
        "# Please login with your Hugging Face token. Make sure to request access to all models on Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiIwTL11ZurU"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"token\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My6rGO-g0NPG"
      },
      "source": [
        "# Tasks Names Defined Below (You should see how to define tasks in src/tasks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioK7fRvdoY4G"
      },
      "source": [
        "1. **NER**: `flare_ner`\n",
        "2. **FINER-ORD**: `flare_finer_ord`\n",
        "3. **FinRED**: `flare_finred`\n",
        "4. **SC**: `flare_causal20_sc`\n",
        "5. **CD**: `flare_cd`\n",
        "6. **FNXL**: `flare_fnxl`\n",
        "7. **FSRL**: `flare_fsrl`\n",
        "8. **FPB**: `flare_fpb`\n",
        "9. **FiQA-SA**: `flare_fiqasa`\n",
        "10. **TSA**: `flare_tsa`\n",
        "11. **Headlines**: `flare_headlines`\n",
        "12. **FOMC**: `flare_fomc`\n",
        "13. **FinArg-ACC**: `flare_finarg_ecc_auc`\n",
        "14. **FinArg-ARC**: `flare_finarg_ecc_arc`\n",
        "15. **MultiFin**: `flare_multifin_en`\n",
        "16. **MA**: `flare_ma`\n",
        "17. **MLESG**: `flare_mlesg`\n",
        "18. **FinQA**: `flare_finqa`\n",
        "19. **TATQA**: `flare_tatqa`\n",
        "20. **Regulations**: (No specific task name provided for this)\n",
        "21. **ConvFinQA**: `flare_convfinqa`\n",
        "22. **EDTSUM**: `flare_edtsum`\n",
        "23. **ECTSUM**: `flare_ectsum`\n",
        "24. **BigData22**: `flare_sm_bigdata`\n",
        "25. **ACL18**: `flare_sm_acl`\n",
        "26. **CIKM18**: `flare_sm_cikm`\n",
        "27. **German**: `flare_german`\n",
        "28. **Australian**: `flare_australian`\n",
        "29. **LendingClub**: `flare_cra_lendingclub`\n",
        "30. **ccf**: `flare_cra_ccf`\n",
        "31. **ccfraud**: `flare_cra_ccfraud`\n",
        "32. **polish**: `flare_cra_polish`\n",
        "33. **taiwan**: `flare_cra_taiwan`\n",
        "34. **portoseguro**: `flare_cra_portoseguro`\n",
        "35. **travelinsurance**: `flare_cra_travelinsurace`\n",
        "36. **ES_FinanceES**: `flare_es_financees`\n",
        "37. **ES_Multifin**: `flare_es_multifin`\n",
        "38. **ES_EFP**: `flare_es_efp`\n",
        "39. **ES_EFPA**: `flare_es_efpa`\n",
        "40. **ES_FNS**: `flare_es_fns`\n",
        "41. **ES_TSA**: `flare_es_tsa`\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tasks_list = [\n",
        "    \"flare_ner\",\n",
        "    \"flare_finer_ord\",\n",
        "    \"flare_finred\",\n",
        "    \"flare_causal20_sc\",\n",
        "    \"flare_cd\",\n",
        "    \"flare_fnxl\",\n",
        "    \"flare_fsrl\",\n",
        "    \"flare_fpb\",\n",
        "    \"flare_fiqasa\",\n",
        "    \"flare_tsa\",\n",
        "    \"flare_headlines\",\n",
        "    \"flare_fomc\",\n",
        "    \"flare_finarg_ecc_auc\",\n",
        "    \"flare_finarg_ecc_arc\",\n",
        "    \"flare_multifin_en\",\n",
        "    \"flare_ma\",\n",
        "    \"flare_mlesg\",\n",
        "    \"flare_finqa\",\n",
        "    \"flare_tatqa\",\n",
        "    # \"Regulations\"\n",
        "    \"flare_convfinqa\",\n",
        "    \"flare_edtsum\",\n",
        "    \"flare_ectsum\",\n",
        "    \"flare_sm_bigdata\",\n",
        "    \"flare_sm_acl\",\n",
        "    \"flare_sm_cikm\",\n",
        "    \"flare_german\",\n",
        "    \"flare_australian\",\n",
        "    \"flare_cra_lendingclub\",\n",
        "    \"flare_cra_ccf\",\n",
        "    \"flare_cra_ccfraud\",\n",
        "    \"flare_cra_polish\",\n",
        "    \"flare_cra_taiwan\",\n",
        "    \"flare_cra_portoseguro\",\n",
        "    \"flare_cra_travelinsurace\",\n",
        "    \"flare_es_financees\",\n",
        "    \"flare_es_multifin\",\n",
        "    \"flare_es_efp\",\n",
        "    \"flare_es_efpa\",\n",
        "    \"flare_es_fns\",\n",
        "    \"flare_es_tsa\"\n",
        "]"
      ],
      "metadata": {
        "id": "hTZTevLeI0bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "tokenizer = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "max_gen_toks = 512\n",
        "batch_size = 20000\n",
        "num_fewshot = 0\n",
        "results_dir = \"/content/results\"\n",
        "model_type = \"hf-causal-vllm\"\n",
        "model_name = \"DeepSeek-R1-Distill-Llama-8B\""
      ],
      "metadata": {
        "id": "uPhaArMuJRQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(f\"{results_dir}/{model_name}\", exist_ok=True)"
      ],
      "metadata": {
        "id": "mezs1_gnKeSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for task in tasks_list:\n",
        "    output_file_path = f\"{results_dir}/{model_name}/{task}_results.txt\"\n",
        "    print(f\"Running task: {task}\\nSaving output to: {output_file_path}\\n\")\n",
        "\n",
        "    !python PIXIU/src/eval.py \\\n",
        "        --model $model_type \\\n",
        "        --model_args \"pretrained=$pretrained,tokenizer=$tokenizer,trust_remote_code=True,use_fast=False,max_gen_toks=$max_gen_toks\" \\\n",
        "        --tasks $task \\\n",
        "        --batch_size $batch_size \\\n",
        "        --num_fewshot $num_fewshot \\\n",
        "        --output_base_path $results_dir \\\n",
        "        > $output_file_path"
      ],
      "metadata": {
        "id": "zGG5_tkAI72j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OtCTao9m22-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMVOzzXP23Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tofAHGYc23Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below are more examples of evaluating models**`"
      ],
      "metadata": {
        "id": "qaq4Gour2rmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "tokenizer = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "max_gen_toks = 512\n",
        "batch_size = 20000\n",
        "num_fewshot = 0\n",
        "results_dir = \"/content/results\"\n",
        "model_type = \"hf-causal-vllm\"\n",
        "model_name = \"DeepSeek-R1-Distill-Qwen-1.5B\""
      ],
      "metadata": {
        "id": "1y1ih3fCO7zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(f\"{results_dir}/{model_name}\", exist_ok=True)"
      ],
      "metadata": {
        "id": "2CSDiO_3PMcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for task in tasks_list:\n",
        "    output_file_path = f\"{results_dir}/{model_name}/{task}_results.txt\"\n",
        "    print(f\"Running task: {task}\\nSaving output to: {output_file_path}\\n\")\n",
        "\n",
        "    !python PIXIU/src/eval.py \\\n",
        "        --model $model_type \\\n",
        "        --model_args \"pretrained=$pretrained,tokenizer=$tokenizer,trust_remote_code=True,use_fast=False,max_gen_toks=$max_gen_toks\" \\\n",
        "        --tasks $task \\\n",
        "        --batch_size $batch_size \\\n",
        "        --num_fewshot $num_fewshot \\\n",
        "        --output_base_path $results_dir \\\n",
        "        > $output_file_path"
      ],
      "metadata": {
        "id": "8wYuKenPPO1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r results.zip /content/results"
      ],
      "metadata": {
        "id": "xfNjE5PKJ0uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('results.zip')"
      ],
      "metadata": {
        "id": "5LYbQhW_J2-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO5Ez_yNnQuj"
      },
      "source": [
        "# Using a Hugging Face Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y3oortLCg3D"
      },
      "outputs": [],
      "source": [
        "!python PIXIU/src/eval.py \\\n",
        "    --model \"hf-causal-vllm\" \\\n",
        "    --model_args \"pretrained=codellama/CodeLlama-7b-hf,tokenizer=codellama/CodeLlama-7b-hf,trust_remote_code=True,use_fast=False,max_gen_toks=25\" \\\n",
        "    --tasks \"flare_es_multifin\" \\\n",
        "    --batch_size 20000 \\\n",
        "    --num_fewshot 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1baNiIJEnz-L"
      },
      "outputs": [],
      "source": [
        "!python PIXIU/src/eval.py \\\n",
        "    --model \"hf-causal-vllm\" \\\n",
        "    --model_args \"pretrained=Qwen/Qwen2-7B-Instruct,tokenizer=Qwen/Qwen2-7B-Instruct,dtype=float16,use_fast=False,max_gen_toks=128\" \\\n",
        "    --tasks \"flare_edtsum\" \\\n",
        "    --batch_size 20000 \\\n",
        "    --num_fewshot 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCaGYOuzoxkP"
      },
      "outputs": [],
      "source": [
        "!python PIXIU/src/eval.py \\\n",
        "    --model \"hf-causal-vllm\" \\\n",
        "    --model_args \"pretrained=google/gemma-2-9b-it,tokenizer=google/gemma-2-9b-it,dtype=float16,use_fast=False,max_gen_toks=128\" \\\n",
        "    --tasks \"flare_fnxl\" \\\n",
        "    --batch_size 20000 \\\n",
        "    --num_fewshot 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mSzvedWzu-i"
      },
      "source": [
        "# Using a Model from the Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqLVdw2Vnui3"
      },
      "outputs": [],
      "source": [
        "!python PIXIU/src/eval.py \\\n",
        "    --model \"hf-causal-vllm\" \\\n",
        "    --model_args \"pretrained=meta-llama/Llama-2-7b-chat-hf,peft=xiangr/fingpt-forecaster_dow30_llama2-7b_lora,tokenizer=meta-llama/Llama-2-7b-chat-hf,dtype=float16,use_fast=False,max_gen_toks=25\" \\\n",
        "    --tasks \"flare_es_efpa\" \\\n",
        "    --batch_size 20000 \\\n",
        "    --num_fewshot 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZGyGwzuTtcr"
      },
      "outputs": [],
      "source": [
        "!python PIXIU/src/eval.py \\\n",
        "    --model \"hf-causal-vllm\" \\\n",
        "    --model_args \"pretrained=meta-llama/Llama-2-7b-chat-hf,peft=xiangr/fingpt-forecaster_dow30_llama2-7b_lora,tokenizer=meta-llama/Llama-2-7b-chat-hf,dtype=float16,use_fast=False,max_gen_toks=25\" \\\n",
        "    --tasks \"flare_es_fns\" \\\n",
        "    --batch_size 20000 \\\n",
        "    --num_fewshot 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrDjPP4XTusU"
      },
      "outputs": [],
      "source": [
        "!python PIXIU/src/eval.py \\\n",
        "    --model \"hf-causal-vllm\" \\\n",
        "    --model_args \"pretrained=meta-llama/Llama-2-7b-chat-hf,peft=xiangr/fingpt-forecaster_dow30_llama2-7b_lora,tokenizer=meta-llama/Llama-2-7b-chat-hf,dtype=float16,use_fast=False,max_gen_toks=25\" \\\n",
        "    --tasks \"flare_es_financees\" \\\n",
        "    --batch_size 20000 \\\n",
        "    --num_fewshot 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hK4EXAEYrWA"
      },
      "outputs": [],
      "source": [
        "!python PIXIU/src/eval.py \\\n",
        "    --model \"hf-causal-vllm\" \\\n",
        "    --model_args \"pretrained=meta-llama/Llama-2-7b-chat-hf,peft=xiangr/fingpt-forecaster_dow30_llama2-7b_lora,tokenizer=meta-llama/Llama-2-7b-chat-hf,dtype=float16,use_fast=False,max_gen_toks=25\" \\\n",
        "    --tasks \"flare_es_tsa\" \\\n",
        "    --batch_size 20000 \\\n",
        "    --num_fewshot 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}